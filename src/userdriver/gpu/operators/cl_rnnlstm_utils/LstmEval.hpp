#pragma once

#include "userdriver/gpu/common/CLRuntime.hpp"
#include "userdriver/gpu/common/CLTensor.hpp"
#include "userdriver/common/operator_interfaces/common/ActivationInfo.hpp"
#include "userdriver/common/operator_interfaces/common/Common.hpp"

namespace enn {
namespace ud {
namespace gpu {

Status evalFloat(const std::shared_ptr<CLRuntime> runtime,
                 const PrecisionType &precision,
                 const std::shared_ptr<CLTensor> input,
                 const std::shared_ptr<CLTensor> input_to_input_weights,
                 const std::shared_ptr<CLTensor> input_to_forget_weights,
                 const std::shared_ptr<CLTensor> input_to_cell_weights,
                 const std::shared_ptr<CLTensor> input_to_output_weights,
                 const std::shared_ptr<CLTensor> recurrent_to_input_weights,
                 const std::shared_ptr<CLTensor> recurrent_to_forget_weights,
                 const std::shared_ptr<CLTensor> recurrent_to_cell_weights,
                 const std::shared_ptr<CLTensor> recurrent_to_output_weights,
                 const std::shared_ptr<CLTensor> cell_to_input_weights,
                 const std::shared_ptr<CLTensor> cell_to_forget_weights,
                 const std::shared_ptr<CLTensor> cell_to_output_weights,
                 const std::shared_ptr<CLTensor> aux_input,
                 const std::shared_ptr<CLTensor> aux_input_to_input_weights,
                 const std::shared_ptr<CLTensor> aux_input_to_forget_weights,
                 const std::shared_ptr<CLTensor> aux_input_to_cell_weights,
                 const std::shared_ptr<CLTensor> aux_input_to_output_weights,
                 const std::shared_ptr<CLTensor> input_gate_bias,
                 const std::shared_ptr<CLTensor> forget_gate_bias,
                 const std::shared_ptr<CLTensor> cell_bias,
                 const std::shared_ptr<CLTensor> output_gate_bias,
                 const std::shared_ptr<CLTensor> projection_weights,
                 const std::shared_ptr<CLTensor> projection_bias,
                 const int max_time,
                 const int n_batch,
                 const int n_input,
                 const int aux_input_size,
                 const int n_cell,
                 const int n_output,
                 const int output_batch_leading_dim,
                 const ActivationInfo activate_info,
                 const float cell_clip,
                 const float proj_clip,
                 bool forward_sequence,
                 uint32_t output_offset,
                 std::shared_ptr<CLTensor> input_gate_scratch,
                 std::shared_ptr<CLTensor> forget_gate_scratch,
                 std::shared_ptr<CLTensor> cell_gate_scratch,
                 std::shared_ptr<CLTensor> output_gate_scratch,
                 std::shared_ptr<CLTensor> activation_state,
                 std::shared_ptr<CLTensor> cell_state,
                 std::shared_ptr<CLTensor> output,
                 bool use_layer_norm = false,
                 std::shared_ptr<CLTensor> output_state_out = nullptr,
                 std::shared_ptr<CLTensor> cell_state_out = nullptr);

Status evalFloatOpt(const std::shared_ptr<CLRuntime> runtime,
                    const PrecisionType &precision,
                    const std::shared_ptr<CLTensor> input,
                    const std::shared_ptr<CLTensor> input_output_concat,
                    const std::shared_ptr<CLTensor> input_recurrent_to_4gate_weights,
                    const std::shared_ptr<CLTensor> gate4_bias,
                    const int max_time,
                    const int n_batch,
                    const int n_input,
                    const int n_cell,
                    const int n_output,
                    const int output_batch_leading_dim,
                    const float proj_clip,
                    bool forward_sequence,
                    uint32_t output_offset,
                    std::shared_ptr<CLTensor> input_gate_scratch,
                    std::shared_ptr<CLTensor> forget_gate_scratch,
                    std::shared_ptr<CLTensor> cell_gate_scratch,
                    std::shared_ptr<CLTensor> output_gate_scratch,
                    std::shared_ptr<CLTensor> activation_state,
                    std::shared_ptr<CLTensor> cell_state,
                    std::shared_ptr<CLTensor> output);

Status layerNormLstmEvalFloat(const std::shared_ptr<CLRuntime> runtime,
                              const PrecisionType &precision,
                              const std::shared_ptr<CLTensor> input,
                              const std::shared_ptr<CLTensor> input_to_input_weights,
                              const std::shared_ptr<CLTensor> input_to_forget_weights,
                              const std::shared_ptr<CLTensor> input_to_cell_weights,
                              const std::shared_ptr<CLTensor> input_to_output_weights,
                              const std::shared_ptr<CLTensor> recurrent_to_input_weights,
                              const std::shared_ptr<CLTensor> recurrent_to_forget_weights,
                              const std::shared_ptr<CLTensor> recurrent_to_cell_weights,
                              const std::shared_ptr<CLTensor> recurrent_to_output_weights,
                              const std::shared_ptr<CLTensor> cell_to_input_weights,
                              const std::shared_ptr<CLTensor> cell_to_forget_weights,
                              const std::shared_ptr<CLTensor> cell_to_output_weights,
                              const std::shared_ptr<CLTensor> input_layer_norm_weights,
                              const std::shared_ptr<CLTensor> forget_layer_norm_weights,
                              const std::shared_ptr<CLTensor> cell_layer_norm_weights,
                              const std::shared_ptr<CLTensor> output_layer_norm_weights,
                              const std::shared_ptr<CLTensor> input_gate_bias,
                              const std::shared_ptr<CLTensor> forget_gate_bias,
                              const std::shared_ptr<CLTensor> cell_gate_bias,
                              const std::shared_ptr<CLTensor> output_gate_bias,
                              const std::shared_ptr<CLTensor> projection_weights,
                              const std::shared_ptr<CLTensor> projection_bias,
                              const int n_batch,
                              const int n_input,
                              const int n_cell,
                              const int n_output,
                              const ActivationInfo activate_info,
                              const float cell_clip,
                              const float proj_clip,
                              const float layer_norm_epsilon,
                              std::shared_ptr<CLTensor> input_gate_scratch_buffer,
                              std::shared_ptr<CLTensor> forget_gate_scratch_buffer,
                              std::shared_ptr<CLTensor> cell_gate_scratch_buffer,
                              std::shared_ptr<CLTensor> output_gate_scratch_buffer,
                              std::shared_ptr<CLTensor> activation_state,
                              std::shared_ptr<CLTensor> cell_state,
                              std::shared_ptr<CLTensor> output);

Status evalFloatLayerNorm(const std::shared_ptr<CLRuntime> runtime,
                          const PrecisionType &precision,
                          const std::shared_ptr<CLTensor> input,
                          const std::shared_ptr<CLTensor> input_to_input_weights,
                          const std::shared_ptr<CLTensor> input_to_forget_weights,
                          const std::shared_ptr<CLTensor> input_to_cell_weights,
                          const std::shared_ptr<CLTensor> input_to_output_weights,
                          const std::shared_ptr<CLTensor> recurrent_to_input_weights,
                          const std::shared_ptr<CLTensor> recurrent_to_forget_weights,
                          const std::shared_ptr<CLTensor> recurrent_to_cell_weights,
                          const std::shared_ptr<CLTensor> recurrent_to_output_weights,
                          const std::shared_ptr<CLTensor> cell_to_input_weights,
                          const std::shared_ptr<CLTensor> cell_to_forget_weights,
                          const std::shared_ptr<CLTensor> cell_to_output_weights,
                          const std::shared_ptr<CLTensor> input_layer_norm_weights,
                          const std::shared_ptr<CLTensor> forget_layer_norm_weights,
                          const std::shared_ptr<CLTensor> cell_layer_norm_weights,
                          const std::shared_ptr<CLTensor> output_layer_norm_weights,
                          const std::shared_ptr<CLTensor> input_gate_bias,
                          const std::shared_ptr<CLTensor> forget_gate_bias,
                          const std::shared_ptr<CLTensor> cell_bias,
                          const std::shared_ptr<CLTensor> output_gate_bias,
                          const std::shared_ptr<CLTensor> projection_weights,
                          const std::shared_ptr<CLTensor> projection_bias,
                          const int max_time,
                          const int n_batch,
                          const int n_input,
                          const int n_cell,
                          const int n_output,
                          const int output_batch_leading_dim,
                          const ActivationInfo activate_info,
                          const float cell_clip,
                          const float proj_clip,
                          const float layer_norm_epsilon,
                          bool forward_sequence,
                          uint32_t output_offset,
                          std::shared_ptr<CLTensor> input_gate_scratch,
                          std::shared_ptr<CLTensor> forget_gate_scratch,
                          std::shared_ptr<CLTensor> cell_gate_scratch,
                          std::shared_ptr<CLTensor> output_gate_scratch,
                          std::shared_ptr<CLTensor> activation_state,
                          std::shared_ptr<CLTensor> cell_state,
                          std::shared_ptr<CLTensor> output,
                          std::shared_ptr<CLTensor> output_state_out = nullptr,
                          std::shared_ptr<CLTensor> cell_state_out = nullptr);

}  // namespace gpu
}  // namespace ud
}  // namespace enn
